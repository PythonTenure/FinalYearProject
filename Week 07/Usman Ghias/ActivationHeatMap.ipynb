{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345a93df-612e-414d-82f2-f32a14da90c6",
   "metadata": {},
   "source": [
    "# $$ Activation Heat Map $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450ca70-75b6-461c-90f2-a7a0d0017ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b4628-d34f-4ecc-8529-f4cd7b3125c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import numpy as np \n",
    "#from patchify import patchify\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e0953-6724-44cb-8177-bd70dc943be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368a8a7-b7ba-4211-a788-453e823403c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_folder = '/content/drive/MyDrive/Colab Notebooks/datasets/satellite/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9044be9-c441-4195-a19d-b66b07fc3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"DubaiDataset/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31838979-2017-4a18-86fb-9528d9e80760",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_patch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848a04d-c01a-41d5-be34-3149a3b11179",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "for image_type in ['images' , 'masks']:\n",
    "  if image_type == 'images':\n",
    "    image_extension = 'jpg'\n",
    "  elif image_type == 'masks':\n",
    "     image_extension = 'png'\n",
    "  for tile_id in range(1,8):\n",
    "    for image_id in range(1,20):\n",
    "      image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/{image_type}/image_part_00{image_id}.{image_extension}',1)\n",
    "      if image is not None:\n",
    "        if image_type == 'masks':\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #print(image.shape)\n",
    "        size_x = (image.shape[1]//image_patch_size)*image_patch_size\n",
    "        size_y = (image.shape[0]//image_patch_size)*image_patch_size\n",
    "        #print(\"{} --- {} - {}\".format(image.shape, size_x, size_y))\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.crop((0,0, size_x, size_y))\n",
    "        #print(\"({},  {})\".format(image.size[0],image.size[1]))\n",
    "        image = np.array(image)\n",
    "        patched_images = patchify(image, (image_patch_size, image_patch_size, 3), step=image_patch_size)\n",
    "        #print(len(patched_images))\n",
    "        for i in range(patched_images.shape[0]):\n",
    "          for j in range(patched_images.shape[1]):\n",
    "            if image_type == 'images':\n",
    "              individual_patched_image = patched_images[i,j,:,:]\n",
    "              #print(individual_patched_image.shape)\n",
    "              individual_patched_image = minmaxscaler.fit_transform(individual_patched_image.reshape(-1, individual_patched_image.shape[-1])).reshape(individual_patched_image.shape)\n",
    "              individual_patched_image = individual_patched_image[0]\n",
    "              #print(individual_patched_image.shape)\n",
    "              image_dataset.append(individual_patched_image)\n",
    "            elif image_type == 'masks':\n",
    "              individual_patched_mask = patched_images[i,j,:,:]\n",
    "              individual_patched_mask = individual_patched_mask[0]\n",
    "              mask_dataset.append(individual_patched_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25094a6-0738-4626-9301-96d69e6b217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mage_dataset = np.array(image_dataset)\n",
    "mask_dataset = np.array(mask_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c65010-6996-4acc-a662-90daafafe759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_dataset))\n",
    "print(len(mask_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29177d6d-afdc-49cb-bc7f-b55d0c25dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_id = random.randint(0, len(image_dataset))\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_dataset[random_image_id])\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_dataset[random_image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27a96f-a556-44fa-94d8-41b8b0666ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_building = '#3C1098'\n",
    "class_building = class_building.lstrip('#')\n",
    "class_building = np.array(tuple(int(class_building[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_building)\n",
    "\n",
    "class_land = '#8429F6'\n",
    "class_land = class_land.lstrip('#')\n",
    "class_land = np.array(tuple(int(class_land[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_land)\n",
    "\n",
    "class_road = '#6EC1E4'\n",
    "class_road = class_road.lstrip('#')\n",
    "class_road = np.array(tuple(int(class_road[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_road)\n",
    "\n",
    "class_vegetation = '#FEDD3A'\n",
    "class_vegetation = class_vegetation.lstrip('#')\n",
    "class_vegetation = np.array(tuple(int(class_vegetation[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_vegetation)\n",
    "\n",
    "class_water = '#E2A929'\n",
    "class_water = class_water.lstrip('#')\n",
    "class_water = np.array(tuple(int(class_water[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_water)\n",
    "\n",
    "class_unlabeled = '#9B9B9B'\n",
    "class_unlabeled = class_unlabeled.lstrip('#')\n",
    "class_unlabeled = np.array(tuple(int(class_unlabeled[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b75004d-f421-4953-9353-d3e961482314",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = individual_patched_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d882f6d-61ce-4dfb-a79c-028d697ae124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_label(label):\n",
    "  label_segment = np.zeros(label.shape, dtype=np.uint8)\n",
    "  label_segment[np.all(label == class_water, axis=-1)] = 0\n",
    "  label_segment[np.all(label == class_land, axis=-1)] = 1\n",
    "  label_segment[np.all(label == class_road, axis=-1)] = 2\n",
    "  label_segment[np.all(label == class_building, axis=-1)] = 3\n",
    "  label_segment[np.all(label == class_vegetation, axis=-1)] = 4\n",
    "  label_segment[np.all(label == class_unlabeled, axis=-1)] = 5\n",
    "  #print(label_segment)\n",
    "  label_segment = label_segment[:,:,0]\n",
    "  #print(label_segment)\n",
    "  return label_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130ef7c-b764-49da-92bc-d8eb100425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(mask_dataset.shape[0]):\n",
    "  label = rgb_to_label(mask_dataset[i])\n",
    "  labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353b058-c564-491b-ad6a-191db93273e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "labels = np.expand_dims(labels, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0bbd5-1669-4ea5-9cbc-98195c86decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858cf0a7-25b0-45f0-94f8-93feea5c9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total unique labels based on masks: \",format(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc126d-4762-4486-bf7e-fe7d6d4beddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_id = random.randint(0, len(image_dataset))\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_dataset[random_image_id])\n",
    "plt.subplot(122)\n",
    "#plt.imshow(mask_dataset[random_image_id])\n",
    "plt.imshow(labels[random_image_id][:,:,0])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b17ec5-0d53-4f04-935c-8c7ccb07602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_classes = len(np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7309fd-a515-4ee6-85e1-3aca0aaab278",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d0d12-8c26-40f5-b36c-eae1fed63e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc79fd4-1d70-4492-8142-79b67fe15864",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_categorical_dataset = to_categorical(labels, num_classes=total_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084cbcc1-31f8-4dcc-9b0f-fdf143f7fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_trianing_dataset = image_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76abee5-4609-4b30-a33a-fb4629495fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c8910-82dc-4fcb-a9cf-869861acc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(master_trianing_dataset, labels_categorical_dataset, test_size=0.15, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0465f74-6bab-4036-83b0-a64af0505aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896924f-bcd2-4924-a916-0bb1563c3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = X_train.shape[1]\n",
    "image_width = X_train.shape[2]\n",
    "image_channels = X_train.shape[3]\n",
    "total_classes = y_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d06fc-989e-4a42-b6ad-57242e7baa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(image_height)\n",
    "print(image_width)\n",
    "print(image_channels)\n",
    "print(total_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46c877-1063-482a-9de7-c941f8008c0d",
   "metadata": {},
   "source": [
    "# $$ Part 02 - Starts Here $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dfd91c-d8f5-4d13-b45b-e61d28566475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U segmentation-models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76205fa7-7fab-4088-9ad8-0852e565883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import concatenate, BatchNormalization, Dropout, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd5eae-8cbc-4dc6-be48-69eaabdcea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd7010-d824-439f-aa0f-d2ecac843b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "  y_true_flatten = K.flatten(y_true)\n",
    "  y_pred_flatten = K.flatten(y_pred)\n",
    "  intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
    "  final_coef_value = (intersection + 1.0) / (K.sum(y_true_flatten) + K.sum(y_pred_flatten) - intersection + 1.0)\n",
    "  return final_coef_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58bd07-1b36-44b0-87bf-6b601824c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multi_unet_model(n_classes=5, image_height=256, image_width=256, image_channels=1):\n",
    "\n",
    "  inputs = Input((image_height, image_width, image_channels))\n",
    "\n",
    "  source_input = inputs\n",
    "\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
    "  c1 = Dropout(0.2)(c1)\n",
    "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "  p1 = MaxPooling2D((2,2))(c1)\n",
    "\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "  c2 = Dropout(0.2)(c2)\n",
    "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "  p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "  c3 = Dropout(0.2)(c3)\n",
    "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "  p3 = MaxPooling2D((2,2))(c3)\n",
    "\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "  c4 = Dropout(0.2)(c4)\n",
    "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "  p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "  c5 = Dropout(0.2)(c5)\n",
    "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
    "\n",
    "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
    "  u6 = concatenate([u6, c4])\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "  c6 = Dropout(0.2)(c6)\n",
    "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
    "  u7 = concatenate([u7, c3])\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "  c7 = Dropout(0.2)(c7)\n",
    "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
    "  u8 = concatenate([u8, c2])\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "  c8 = Dropout(0.2)(c8)\n",
    "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
    "  u9 = concatenate([u9, c1], axis=3)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "  c9 = Dropout(0.2)(c9)\n",
    "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "  outputs = Conv2D(n_classes, (1,1), activation=\"softmax\")(c9)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee853d-e9b4-4887-8b7a-4321774ee6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = [\"accuracy\", jaccard_coef]\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9db0b2-4ed1-44d6-ab0c-b8f99e7fca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(image_height)\n",
    "print(image_width)\n",
    "print(image_channels)\n",
    "print(total_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fae3b-12c5-4a18-945f-8428978ea0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_learning_model():\n",
    "  return multi_unet_model(n_classes=total_classes, \n",
    "                          image_height=image_height, \n",
    "                          image_width=image_width, \n",
    "                          image_channels=image_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8a5a1-bfd8-40aa-980c-5402a6f72343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_deep_learning_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25dd41-a637-4c4f-8708-726c9e76e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Please uncomment this line to get model confiuration\n",
    "# model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d2a84-4ccf-4d70-82ef-cf1077b16a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating Loss Function\n",
    "- dice loss > Focal Loss > Total Loss\n",
    "- Total Loss = (Dice loss + (1*Focal Loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76fabe-41a6-4a83-b842-a8b236830978",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4a4a7-c9db-4bae-8d60-604175ae2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb7d2d-f893-45d3-aef0-298c8f7cf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = sm.losses.DiceLoss(class_weights = weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4907f27-840d-4cb0-83ea-f60de4d2daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = sm.losses.CategoricalFocalLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561a2da-f69c-41ba-8ade-8f02d449a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = dice_loss + (1 * focal_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8343c7-c29d-46e6-a1bc-f3d40977bae5",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6f7e7-e7aa-45d4-9bc8-5df1d9096aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22357586-cb95-42fb-9a76-a573a49a63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d178c-9cae-462a-a281-3c8d8ddbfa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=total_loss, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2b971-2c8e-4d65-8251-b0199dc6db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289a497-fb96-446e-ab90-6efa82467071",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(X_train, y_train,\n",
    "                          batch_size=16,\n",
    "                          verbose=1,\n",
    "                          epochs=100,\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a76a0-f10b-449c-be8b-574c30abf0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_a = model_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0398e-2af8-4ffd-83da-c46edba06107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history_a.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db38846-95c4-4efe-b6d4-0f5a2c6f0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history_a.history['loss']\n",
    "val_loss = history_a.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
    "plt.title(\"Training Vs Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4f72f-5b1f-4539-8a28-88acc46d8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_coef = history_a.history['jaccard_coef']\n",
    "val_jaccard_coef = history_a.history['val_jaccard_coef']\n",
    "\n",
    "epochs = range(1, len(jaccard_coef) + 1)\n",
    "plt.plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
    "plt.plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
    "plt.title(\"Training Vs Validation IoU\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e7ef5-93ab-41a2-9b4e-1ca2ea4a2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec9c0a-5bb5-4661-b5e7-78036cd9132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955c1f3-0000-4546-b4a3-aa8a9f0ab57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd25aa3-1e81-4202-9548-02b625763642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664f425-302c-4bac-a4b1-7c433eca3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd038aa-3871-427e-874d-a3e5551b30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_argmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3042b2e-55f4-482d-bc1c-4d7f10782080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_argmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a6fa2-77bf-4b22-8caf-a15ea9544e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_argmax = np.argmax(y_test, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e16b5-5f2e-4bbf-9227-d3fa99f4c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_argmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d38bdf-2629-402d-bfda-db1358398000",
   "metadata": {},
   "source": [
    "## Comparing prediction results\n",
    "- using test images using mask images and predicted result images.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b3596-48c7-4847-83e6-c4ae44fa59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15964dda-c961-41b6-b2de-d69ea654edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_number = random.randint(0, len(X_test))\n",
    "\n",
    "test_image = X_test[test_image_number]\n",
    "ground_truth_image = y_test_argmax[test_image_number]\n",
    "\n",
    "test_image_input = np.expand_dims(test_image, 0)\n",
    "\n",
    "prediction = saved_model.predict(test_image_input)\n",
    "#prediction = model.predict(test_image_input)\n",
    "predicted_image = np.argmax(prediction, axis=3)\n",
    "predicted_image = predicted_image[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550f138-085b-417b-9b7a-4228bcff2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(231)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(test_image)\n",
    "plt.subplot(232)\n",
    "plt.title(\"Original Masked image\")\n",
    "plt.imshow(ground_truth_image)\n",
    "plt.subplot(233)\n",
    "plt.title(\"Predicted Image\")\n",
    "plt.imshow(predicted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a90f3-6e28-494a-9f3d-de7c45ec4aab",
   "metadata": {},
   "source": [
    "## Model saving and reloading (with custom loss and custom metrics)\n",
    "- loss\n",
    "    - 'dice_loss_plus_1focal_loss': total_loss\n",
    "- Metrics\n",
    "    - jaccard_coef: jaccard_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f52e0-b4ca-410e-a6d6-a533521d112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd577809-5df9-4988-a377-27265019ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('satellite-imagery.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4829c-5341-41d0-b8d3-7684160e981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442eaa1-5cb4-42e7-9f68-4fa6b2bee023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03073b22-8ec5-466e-be4b-f561a39ad0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = load_model('/content/satellite-imagery.h5',\n",
    "                         custom_objects=({'dice_loss_plus_1focal_loss': total_loss, \n",
    "                                          'jaccard_coef': jaccard_coef}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44409e-4f9b-4eca-9119-6c466785edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.loss.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368be1f-9de0-449a-bfd8-a29a873c6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_model.get_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040cb02-ca9a-4ce3-98a8-d8385de10daf",
   "metadata": {},
   "source": [
    "## Performing Prediction using the custom image from Google Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d8db5-9885-4de1-a5d9-6ccb8d550206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/fc-img1.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad88c6f-2a33-49d7-a61e-d9e4f1c5ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/fc-img2.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f760ca-60ca-4517-bfb7-0cccccd01456",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('/content/fc-img1.jpg')\n",
    "image = image.resize((256,256))\n",
    "image = np.array(image)\n",
    "image = np.expand_dims(image, 0)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe52a36-8739-4d72-aefe-6102f9bac25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = saved_model.predict(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433634d-ccc8-43e6-8cc8-741221c999af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_image = np.argmax(prediction, axis=3)\n",
    "predicted_image = predicted_image[0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b05cc0-bfcd-43d8-b309-adbc2be8ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(231)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(Image.open('/content/fc-img1.jpg'))\n",
    "plt.subplot(232)\n",
    "plt.title(\"Predicted Image\")\n",
    "plt.imshow(predicted_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5259ca0-e7a6-4b05-8d95-f48221cebe8b",
   "metadata": {},
   "source": [
    "## Collecting Activation and gradients output from Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407a578-b999-4d85-a903-1ce07e15970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a66fd3-a81f-455d-92e9-917c24247b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keract as ke\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c043b3d-3e69-4cec-b7b2-f22aa7a7cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = ke.get_activations(saved_model, image, nodes_to_evaluate=None, output_format='simple', auto_compile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfea26d-dfaf-462c-927a-d54a084f553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lah /content/activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a105b3-3c4c-4afc-b4cd-afdb08715345",
   "metadata": {},
   "outputs": [],
   "source": [
    "ke.display_activations(activations, cmap='viridis', save=True, directory='/content/activations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776d354-6c1a-4458-85d2-4fbaa6e9bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/activations/0_input_1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594cd3d-180e-4c6b-9c88-fb29d459d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/activations/1_conv2d.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff7b18-e8dd-4bfb-a498-a082b90f81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/activations/40_conv2d_18.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba403b6-701f-4917-be03-8fc167523fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('/content/fc-img1.jpg')\n",
    "image = image.resize((256,256))\n",
    "image_as_array = np.array(image)\n",
    "image_as_array = image_as_array.astype(np.float32)\n",
    "ke.display_heatmaps(activations, image_as_array, save=True, directory='/content/heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08be01-cf2c-4357-8012-66690175e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/heatmap/0_input_1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a5c6b-5f2a-4987-b34a-ed5a145b8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/heatmap/40_conv2d_18.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bf316-410b-48e1-bb8f-2a2f7c91ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/heatmap/4_max_pooling2d.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799e5df-1da4-4d52-8908-13504c20d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/heatmap/8_max_pooling2d_1.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0f643-21dc-4390-83a1-912f2bca4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/heatmap/12_max_pooling2d_2.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d2c88-54a4-4f03-935c-461e237c5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open('/content/heatmap/16_max_pooling2d_3.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df585b12-7f26-4529-a9eb-62fdeca2ca1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6410f7c-f0f5-4f04-8eea-4036191f42f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4807fd79-7812-4d3d-9b37-e2862124d220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
