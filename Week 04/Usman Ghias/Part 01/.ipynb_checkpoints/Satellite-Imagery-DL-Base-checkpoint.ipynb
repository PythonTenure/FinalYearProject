{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88870c4-bcfe-4b44-97e4-ee50c641628d",
   "metadata": {},
   "source": [
    "# $$ Part 01 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f8521-365f-4f8e-9552-082000f98da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f5ba7-a2d5-4df0-9769-3eafdd285c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import numpy as np \n",
    "from patchify import patchify\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232286f-d27b-4774-a65d-ed3acd7aee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba33abd-8ace-41db-bf9a-4d781a06d129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lah 'D:/GitHub/FinalYearProject/Week 004/Usman Ghias/Part 01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fef581-2513-4da8-9d7f-bb6589f8b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"DubaiDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c562a2-e9e9-4dc6-86f8-cf02a4afdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code uses the os.walk function to traverse through a directory structure.\n",
    "# It explores all subdirectories and files in the specified dataset folder.\n",
    "\n",
    "for path, subdirs, files in os.walk(os.path.join(dataset_root_folder, dataset_name)):\n",
    "    # For each directory (path) in the dataset, extract the directory name.\n",
    "    dir_name = path.split(os.path.sep)[-1]\n",
    "\n",
    "    # Check if the current directory is named 'masks'.\n",
    "    if dir_name == 'masks':\n",
    "        # If it is the 'masks' directory, list all the files (images) in that directory.\n",
    "        images = os.listdir(path)\n",
    "        print(path)  # Print the path to the 'masks' directory.\n",
    "\n",
    "        # Iterate through the list of image files.\n",
    "        for i, image_name in enumerate(images):\n",
    "            # Check if the file has a '.png' extension.\n",
    "            if image_name.endswith('.png'):\n",
    "                # If the file has a '.png' extension, set the variable 'a' to True.\n",
    "                a = True  # You might use this variable for some further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48b263-5686-4769-9aab-a72f3af0198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_patch_size to 256, likely indicating the size (in pixels) for image patches in some image processing task\n",
    "image_patch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee082c4-f35a-48a4-9595-f48088b51b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image using OpenCV (cv2).\n",
    "# The image is loaded from the specified path, which is constructed from 'dataset_root_folder' and 'dataset_name'.\n",
    "# The '1' parameter indicates that the image should be loaded in color (with channels).\n",
    "image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile 2/images/image_part_001.jpg', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69a71d-8092-49b5-8f48-944b59df70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b63cb8-d3d7-4121-bd54-b072a6cd02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image patches using the 'patchify' function with the specified 'image_patch_size' and step size.\n",
    "# 'image' is the input image for patch extraction.\n",
    "# (image_patch_size, image_patch_size, 3) defines the patch size and the number of color channels (3 for color images).\n",
    "# 'step' parameter controls the separation between patches.\n",
    "image_patches = patchify(image, (image_patch_size, image_patch_size, 3), step=image_patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae81ed-6818-4ea3-8099-719ae76f3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15da5d7-4bd5-4bb0-80cf-8fb1ac5ca3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0cdc76-371c-4d96-8121-8cfef668dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscaler = MinMaxScaler()\n",
    "# A Min-Max Scaler is a data preprocessing technique used to scale numeric data to a specific range, often between 0 and 1, \n",
    "# by shifting and scaling the values. It's commonly used in data preprocessing for machine learning and data analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b229a6-351b-435b-b80f-862b0c54e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the first row (index 0) in 'image_y'.\n",
    "image_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dd019-576d-41a3-b620-e6f30c834f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the nearest multiple of 'image_patch_size' that is less than or equal to 'image.shape[0]'.\n",
    "(image.shape[0] // image_patch_size) * image_patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046db5c8-9647-40e8-a8b7-0d519d1be84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687df4b-8258-4aba-9376-327e206a0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image object from the 'image' array and then check its data type using 'type'.\n",
    "type(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04eaa1-479b-45c2-9176-4da4096f4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and return the shape of the 'image' array.\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4756b4-d8e6-4a6f-83ec-76a11b4c168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the nearest multiple of 'image_patch_size' that is less than or equal to 'image.shape[0]'.\n",
    "(image.shape[0] // image_patch_size) * image_patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b0215-c34b-49f8-82fe-cb28cb10bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store image and mask datasets.\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "# Iterate through two types: 'images' and 'masks'.\n",
    "for image_type in ['images', 'masks']:\n",
    "    \n",
    "    # Define the image file extension based on the image type.\n",
    "    if image_type == 'images':\n",
    "        image_extension = 'jpg'\n",
    "    elif image_type == 'masks':\n",
    "        image_extension = 'png'\n",
    "    \n",
    "    # Loop through tile IDs (1 to 7).\n",
    "    for tile_id in range(1, 8):\n",
    "        \n",
    "        # Loop through image IDs (1 to 19).\n",
    "        for image_id in range(1, 20):\n",
    "            \n",
    "            # Load an image using OpenCV based on the specified path.\n",
    "            image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/{image_type}/image_part_00{image_id}.{image_extension}', 1)\n",
    "            \n",
    "            # Check if the image was loaded successfully.\n",
    "            if image is not None:\n",
    "                \n",
    "                # If the image type is 'masks,' convert it to RGB format.\n",
    "                if image_type == 'masks':\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Calculate the size (in pixels) for cropping the image.\n",
    "                size_x = (image.shape[1] // image_patch_size) * image_patch_size\n",
    "                size_y = (image.shape[0] // image_patch_size) * image_patch_size\n",
    "                \n",
    "                # Create an image object from the array, crop it, and convert it back to an array.\n",
    "                image = Image.fromarray(image)\n",
    "                image = image.crop((0, 0, size_x, size_y))\n",
    "                image = np.array(image)\n",
    "                \n",
    "                # Create patches from the image.\n",
    "                patched_images = patchify(image, (image_patch_size, image_patch_size, 3), step=image_patch_size)\n",
    "                \n",
    "                # Loop through the patches.\n",
    "                for i in range(patched_images.shape[0]):\n",
    "                    for j in range(patched_images.shape[1]):\n",
    "                        if image_type == 'images':\n",
    "                            # If the image type is 'images,' preprocess the individual patch.\n",
    "                            individual_patched_image = patched_images[i, j, :, :]\n",
    "                            individual_patched_image = minmaxscaler.fit_transform(individual_patched_image.reshape(-1, individual_patched_image.shape[-1])).reshape(individual_patched_image.shape)\n",
    "                            individual_patched_image = individual_patched_image[0]\n",
    "                            image_dataset.append(individual_patched_image)\n",
    "                        elif image_type == 'masks':\n",
    "                            # If the image type is 'masks,' extract the individual mask patch.\n",
    "                            individual_patched_mask = patched_images[i, j, :, :]\n",
    "                            individual_patched_mask = individual_patched_mask[0]\n",
    "                            mask_dataset.append(individual_patched_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76baa616-67f0-4286-b425-eaae2ffefce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of elements in the 'image_dataset' and 'mask_dataset' lists.\n",
    "print(len(image_dataset))  # Number of elements in the 'image_dataset'.\n",
    "print(len(mask_dataset))   # Number of elements in the 'mask_dataset'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b7569-43b6-41f7-b2e1-0fa35e79caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'image_dataset' and 'mask_dataset' lists into NumPy arrays.\n",
    "image_dataset = np.array(image_dataset)  # Convert 'image_dataset' into a NumPy array.\n",
    "mask_dataset = np.array(mask_dataset)    # Convert 'mask_dataset' into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0ac6f-1f07-41bf-902b-a307838ff762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of elements in the 'image_dataset' and 'mask_dataset' NumPy arrays.\n",
    "print(len(image_dataset))  # Number of elements in the 'image_dataset' NumPy array.\n",
    "print(len(mask_dataset))   # Number of elements in the 'mask_dataset' NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db6478-7ad6-418d-981e-499cc5aba0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and print the data type of the first element in the 'image_dataset' array.\n",
    "type(image_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eeac39-91de-47f4-b5b5-fcf91a53b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and print the data type of the NumPy array obtained by reshaping the first element of 'image_dataset'.\n",
    "type(np.reshape(image_dataset[0], (image_patch_size, image_patch_size, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995beaa0-18f7-473c-b8d9-a3b715c324a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random image ID within the range of available images.\n",
    "random_image_id = random.randint(0, len(image_dataset))\n",
    "\n",
    "# Create a matplotlib figure to display two subplots side by side.\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Define the first subplot (on the left) to display a random image from 'image_dataset'.\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_dataset[random_image_id])  # Display the image.\n",
    "\n",
    "# Define the second subplot (on the right) to display the corresponding mask from 'mask_dataset'.\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_dataset[random_image_id])   # Display the mask."
   ]
  },
  {
   "cell_type": "raw",
   "id": "20528c37-eeca-4309-b309-5d6b50e1fa7e",
   "metadata": {},
   "source": [
    "# Mark down\n",
    "# Define color representations for different classes in hexadecimal format.\n",
    "class_building = '#3C1098'\n",
    "class_land = '#8429F6'\n",
    "class_road = '#6EC1E4'\n",
    "class_vegetation = '#FEDD3A'\n",
    "class_water = '#E2A929'\n",
    "class_unlabeled = '#9B9B9B'\n",
    "\n",
    "# Remove the '#' symbol from each color code and convert it into a NumPy array of RGB values.\n",
    "class_building = np.array(tuple(int(class_building[i:i+2], 16) for i in (0, 2, 4)))\n",
    "class_land = np.array(tuple(int(class_land[i:i+2], 16) for i in (0, 2, 4))\n",
    "class_road = np.array(tuple(int(class_road[i:i+2], 16) for i in (0, 2, 4))\n",
    "class_vegetation = np.array(tuple(int(class_vegetation[i:i+2], 16) for i in (0, 2, 4))\n",
    "class_water = np.array(tuple(int(class_water[i:i+2], 16) for i in (0, 2, 4))\n",
    "class_unlabeled = np.array(tuple(int(class_unlabeled[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# Print the resulting RGB representations of the color codes.\n",
    "print(class_building)\n",
    "print(class_land)\n",
    "print(class_road)\n",
    "print(class_vegetation)\n",
    "print(class_water)\n",
    "print(class_unlabeled)\n",
    "\n",
    "\n",
    "This is raw and don't convert to code of using below one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4daed-c57a-45ef-972d-65b2a9862ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_building = '#3C1098'\n",
    "class_building = class_building.lstrip('#')\n",
    "class_building = np.array(tuple(int(class_building[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_building)\n",
    "\n",
    "class_land = '#8429F6'\n",
    "class_land = class_land.lstrip('#')\n",
    "class_land = np.array(tuple(int(class_land[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_land)\n",
    "\n",
    "class_road = '#6EC1E4'\n",
    "class_road = class_road.lstrip('#')\n",
    "class_road = np.array(tuple(int(class_road[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_road)\n",
    "\n",
    "class_vegetation = '#FEDD3A'\n",
    "class_vegetation = class_vegetation.lstrip('#')\n",
    "class_vegetation = np.array(tuple(int(class_vegetation[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_vegetation)\n",
    "\n",
    "class_water = '#E2A929'\n",
    "class_water = class_water.lstrip('#')\n",
    "class_water = np.array(tuple(int(class_water[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_water)\n",
    "\n",
    "class_unlabeled = '#9B9B9B'\n",
    "class_unlabeled = class_unlabeled.lstrip('#')\n",
    "class_unlabeled = np.array(tuple(int(class_unlabeled[i:i+2], 16) for i in (0,2,4)))\n",
    "print(class_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11735452-1d3d-462b-9caf-35feca9cd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the number of elements (patches) in the first dimension of the 'mask_dataset' NumPy array.\n",
    "mask_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8461f-29ea-4931-ad4c-9f23577d3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the content of the 'individual_patched_mask' variable to a new variable 'label'.\n",
    "label = individual_patched_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5267c49-403a-403b-8606-40584960418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function 'rgb_to_label' to convert an RGB label into a single-channel label segment.\n",
    "def rgb_to_label(label):\n",
    "    # Initialize a new label segment array of the same shape as the input 'label.'\n",
    "    label_segment = np.zeros(label.shape, dtype=np.uint8)\n",
    "\n",
    "    # For each class color (e.g., class_water, class_land), assign a numeric label to 'label_segment.'\n",
    "    # Numeric labels are based on class colors, where 0 represents 'class_water,' 1 represents 'class_land,' and so on.\n",
    "    label_segment[np.all(label == class_water, axis=-1)] = 0\n",
    "    label_segment[np.all(label == class_land, axis=-1)] = 1\n",
    "    label_segment[np.all(label == class_road, axis=-1)] = 2\n",
    "    label_segment[np.all(label == class_building, axis=-1)] = 3\n",
    "    label_segment[np.all(label == class_vegetation, axis=-1)] = 4\n",
    "    label_segment[np.all(label == class_unlabeled, axis=-1)] = 5\n",
    "\n",
    "    # Remove the color channels, leaving a single-channel label segment.\n",
    "    label_segment = label_segment[:, :, 0]\n",
    "\n",
    "    # Return the resulting label segment.\n",
    "    return label_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d5d1f-e6b2-4b9d-8d39-872c874159e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list 'labels' to store label segments for each mask patch.\n",
    "labels = []\n",
    "\n",
    "# Loop through each mask patch in the 'mask_dataset.'\n",
    "for i in range(mask_dataset.shape[0]):\n",
    "    # Call the 'rgb_to_label' function to convert an RGB mask into a single-channel label segment.\n",
    "    label = rgb_to_label(mask_dataset[i])\n",
    "    \n",
    "    # Append the resulting label segment to the 'labels' list.\n",
    "    labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509c752-1849-4dc8-8968-2f3155d596e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of elements (label segments) in the 'labels' list.\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa73c6-94e9-4110-ab05-fdc9341c8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'labels' list, which contains label segments, into a NumPy array.\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb498635-f07b-471f-8cd5-f0040b2b084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and retrieve the label segment at index 3 in the 'labels' NumPy array.\n",
    "labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207ae89-16aa-4e1d-ad9f-b6525d3ebd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the dimensions of the 'labels' NumPy array by adding a new axis along the third dimension.\n",
    "labels = np.expand_dims(labels, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71861d-ac3e-4cef-8118-e624085062c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and retrieve the label segment at index 0 in the 'labels' NumPy array.\n",
    "labels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c9af3-8fb9-45df-b417-b0c51acde2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the unique values present in the 'labels' NumPy array.\n",
    "np.unique(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417d4bd-aed6-4710-947e-bbf8a18d8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total unique labels based on masks by formatting the result.\n",
    "print(\"Total unique labels based on masks:\", format(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b7226-a501-49bb-b823-5cfadc960c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random image ID within the range of available images.\n",
    "random_image_id = random.randint(0, len(image_dataset))\n",
    "\n",
    "# Create a matplotlib figure to display two subplots side by side.\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Define the first subplot (on the left) to display a random image from 'image_dataset.'\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_dataset[random_image_id])  # Display the image.\n",
    "\n",
    "# Define the second subplot (on the right) to display the corresponding label segment from 'labels.'\n",
    "# The label segment is displayed using the grayscale colormap (single channel).\n",
    "plt.subplot(122)\n",
    "plt.imshow(labels[random_image_id][:, :, 0])  # Display the label segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316ccdb-b647-402e-9fab-a1c9e4f09849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access and retrieve the first label segment's content as a single-channel array from 'labels.'\n",
    "labels[0][:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90063db1-556e-4b7d-9ba2-f54b8ee4e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of unique classes (labels) present in the 'labels' array.\n",
    "total_classes = len(np.unique(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd85d1-3608-4905-bd28-c08c94a17cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and return the total number of unique classes (labels) in the dataset.\n",
    "total_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc853ed-c932-4018-adae-a6953d211040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'to_categorical' function from the TensorFlow module 'keras.utils.'\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e68693-b451-4446-8e26-836b98378cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'labels' array into a categorical representation using one-hot encoding.\n",
    "# 'num_classes' specifies the total number of unique classes.\n",
    "labels_categorical_dataset = to_categorical(labels, num_classes=total_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807da28d-9753-45fc-80ea-326633a3d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and return the shape of the 'labels_categorical_dataset' NumPy array.\n",
    "labels_categorical_dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ae791-a086-4466-8969-7eecf1dab52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 'image_dataset' to the 'master_training_dataset' variable.\n",
    "master_training_dataset = image_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0bb20-452e-4610-9cb1-594ccb639980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'train_test_split' function from the scikit-learn library for data splitting.\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c72980-587a-420d-9518-418b3640a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset and corresponding labels into training and testing subsets.\n",
    "# 'master_trianing_dataset' contains the input data, and 'labels_categorical_dataset' contains the target labels.\n",
    "# 'test_size' specifies the proportion of data to allocate to the testing subset.\n",
    "# 'random_state' sets the random seed for reproducibility.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(master_trianing_dataset, labels_categorical_dataset, test_size=0.15, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909762da-46d8-4119-b78c-5fc55bfaf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes (dimensions) of the training and testing subsets for both data and labels.\n",
    "print(X_train.shape)  # Shape of the training data (X_train).\n",
    "print(X_test.shape)   # Shape of the testing data (X_test).\n",
    "print(y_train.shape)  # Shape of the training labels (y_train).\n",
    "print(y_test.shape)   # Shape of the testing labels (y_test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155c6d7-cf9c-45d5-99e8-382c9d85d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and assign values to variables representing image dimensions and total classes.\n",
    "\n",
    "# 'image_height' stores the height (number of rows) of the images in the training dataset.\n",
    "image_height = X_train.shape[1]\n",
    "\n",
    "# 'image_width' stores the width (number of columns) of the images in the training dataset.\n",
    "image_width = X_train.shape[2]\n",
    "\n",
    "# 'image_channels' represents the number of color channels in the images (e.g., 3 for RGB images).\n",
    "image_channels = X_train.shape[3]\n",
    "\n",
    "# 'total_classes' holds the total number of unique classes in the training labels.\n",
    "total_classes = y_train.shape[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6125a-8d5e-4c9c-8b5f-8e80bbd6f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values of variables representing image dimensions and total classes.\n",
    "\n",
    "print(image_height)    # Print the height of the images in the training dataset.\n",
    "print(image_width)     # Print the width of the images in the training dataset.\n",
    "print(image_channels)  # Print the number of color channels in the images.\n",
    "print(total_classes)   # Print the total number of unique classes in the training labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fd480-7503-446f-829d-6dc10650123c",
   "metadata": {},
   "source": [
    "# $$ Usman Ghias - The END - Part 01 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6f53a-6dbd-4d5c-9aae-b215c97979cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646c1d2a-5bfd-4785-93f7-775592bf989f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
